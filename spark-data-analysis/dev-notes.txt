-this project is for developing data analysis procedures in scala to run on spark.  the basic workflow is like this:
  -generic data transformations can be written in here (things that don't use spark libraries)
  -analysis procedures that call spark libraries can be written in here
  -we may choose to annotate these different things so that a program can provide a ui to use    these different procedures however a user sees fit
  -in order to run on spark, we build everything into an uber jar (excluding spark libraries)    using 'mvn clean install', and submit the jar to a spark cluster, passing the arguments        spark needs to run the procedure (main class, jar location, args, etc)
  -we will probably build a ui tool to make it easy to submit jobs.  we may want to modularize    our analysis procedures so that we can easily chain operations without having to create new    files to do so.  i.e. from the ui, we could have buttons for different analysis procedures,    and create a chain of operations by just clicking the buttons we want in the order we want.
